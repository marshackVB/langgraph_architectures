{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3363be0c-a800-485b-bbeb-1d304f8a38dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "https://langchain-ai.github.io/langgraph/how-tos/graph-api/#add-runtime-configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e156918-4d2e-4e98-8acc-18ad533295a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "builder.add_node(\"position_refined\", position, metadata={\"__my_\": \"his\"})\n",
    "builder.add_node(\"position\", position, metadata={\"__my__\": \"yours\"})\n",
    "....\n",
    "def position(state: State, config: RunnableConfig):\n",
    "  my = config[\"metadata\"][\"__my__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d971513-7c98-46a1-bbbc-af5290010aa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "from langgraph.graph import END, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.runnables.base import RunnableBinding\n",
    "from typing_extensions import TypedDict\n",
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "from agents.rag.tools import documentation_search_tool\n",
    "\n",
    "claude = ChatDatabricks(endpoint=\"databricks-claude-sonnet-4\")\n",
    "llama = ChatDatabricks(endpoint=\"databricks-meta-llama-3-3-70b-instruct\")\n",
    "\n",
    "tools = [documentation_search_tool]\n",
    "claude_with_tools = claude.bind_tools(tools, tool_choice=\"auto\")\n",
    "llama_with_tools = llama.bind_tools(tools, tool_choice=\"auto\")\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "class LlamaSchema(TypedDict):\n",
    "    model_with_tools: RunnableBinding = llama_with_tools\n",
    "\n",
    "class ClaudeSchema(TypedDict):\n",
    "    model_with_tools: RunnableBinding = claude_with_tools\n",
    "\n",
    "class LLMConfig(TypedDict):\n",
    "  model_with_tools: RunnableBinding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b79d005f-7e49-4db8-ba88-cdd932dc1b5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a trusted assistant capable of searching Databricks and Apache Spark documentation. Based on the users most recent question and relevent conversation history, call the documentation search tools you have access to. It's possible that only part of the user's question and recent conversation history is relevent to your area of expertise. Use your judgment to identify which part's of the user's question can be used to retrieved relevent documentation. Make sure your final answer is grounded on the documents returned by the tool.\"\"\"\n",
    "\n",
    "\n",
    "def chatbot(state: MessagesState, config: RunnableConfig):\n",
    "  \"\"\"\n",
    "  Retrieve relevent documents based on the user's question and conversation\n",
    "  history. Answer the user's quesiton based on the documentation.\n",
    "  \"\"\"\n",
    "  messages = [{\"role\": \"system\", \"content\": system_message}] + state[\"messages\"]\n",
    "  print(config[\"configurable\"])\n",
    "  model_with_tools = config[\"configurable\"][\"model_with_tools\"]\n",
    "  response = model_with_tools.invoke(messages)\n",
    "  return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def route_tools(state: MessagesState):\n",
    "  \"\"\"\n",
    "  A router that determines if tools should be called or a final\n",
    "  answer returned to the user\n",
    "  \"\"\"\n",
    "  ai_message = state[\"messages\"][-1]\n",
    "  \n",
    "  if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "  \n",
    "  return END\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import END, MessagesState\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(MessagesState, config_schema=LLMConfig)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\"chatbot\", route_tools,\n",
    "    {\"tools\": \"tools\", \n",
    "      END: END}\n",
    "  ) \n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "rag_agent = graph_builder.compile(name=\"rag_agent\")\n",
    "\n",
    "messages = {\"messages\": [{\"role\": \"user\", \"content\": \"Does Apache Spark support streaming?\"}]}\n",
    "for event in rag_agent.stream(messages, {\"configurable\": {\"model_with_tools\": claude_with_tools}}, stream_mode= \"updates\"):\n",
    "  print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2e16e19-00c7-4cbd-8bad-26c06e92b2f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a725860a-9e14-4f55-a558-3a725e129f6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "messages = {\"messages\": [{\"role\": \"user\", \"content\": \"Does Apache Spark support streaming?\"}]}\n",
    "rag_agent.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "param_test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
