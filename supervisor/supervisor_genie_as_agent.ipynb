{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f11144f1-9e29-4d9d-990c-8324ccd7e1fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Supervisor architecture applied to Genie and RAG\n",
    " - Genie within tool-calling agent\n",
    " - Genie as standalone agent\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20c1a8e0-36e7-4ed0-a105-f5cb95e52d86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "466827f1-710c-44ef-a523-5d78ce5a587d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from chatagent import ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d2fc1a9-2453-4256-82b4-4fcf0f4ba60a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agents.supervisor.graph import app as supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff2b3de0-5bb9-4d39-b109-99cb3cf87459",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from typing import Annotated, TypedDict\n",
    "from typing import Literal, Any\n",
    "from langgraph.types import Command\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from agents.genie.graph import app as genie_agent\n",
    "from agents.rag.graph import app as rag_agent\n",
    "from agents.supervisor.resources.model import model\n",
    "\n",
    "config = mlflow.models.ModelConfig(development_config=\"config.yaml\")\n",
    "genie_config = config.get(\"agents\").get(\"genie\")[0]\n",
    "\n",
    "member_agents = [\"rag\", \"genie\"]\n",
    "options = member_agents + [\"FINISH\"]\n",
    "\n",
    "class Router(TypedDict):\n",
    "    next: Literal[*options]\n",
    "\n",
    "\n",
    "system_prompt = f\"\"\"You are a supervisor tasked with managing a conversation between the following workers: {member_agents}. The worker's capabilities are as follows.\n",
    "                 \n",
    "    - genie: Performs text to SQL against supply chain data tables. \n",
    "    - rag: Retrieves documentation related to Databricks and Apache Spark.\n",
    "\n",
    "Given the following user request respond with the worker to act next. Each worker will perform a task and respond with their results and status. Call only the worker(s) that are important to the user's qeustion. Do not provide insights or summaries of the data returned by the workes. Your only job is to return the work names only. When finished respond with FINISH.\"\"\"\n",
    "\n",
    "\n",
    "def supervisor_node(state: ChatAgentState) -> Command[Literal[*member_agents, \"__end__\"]]:\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state['messages']\n",
    "    supervisor_model = model.with_structured_output(Router)\n",
    "    response = supervisor_model.invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    #goto = response.content\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "    return Command(goto=goto, update={\"next\": goto})\n",
    "  \n",
    "\n",
    "def rag_node(state: ChatAgentState):\n",
    "  response = rag_agent.invoke(state)\n",
    "  return Command(\n",
    "        update={\"messages\": response['messages']},\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def genie_node(state: ChatAgentState):\n",
    "  response = genie_agent.invoke(state)\n",
    "  return Command(\n",
    "        update={\"messages\": response['messages']},\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "  \n",
    "\n",
    "workflow = StateGraph(ChatAgentState)\n",
    "workflow.add_node(\"supervisor\", supervisor_node)\n",
    "workflow.add_node(\"genie\", genie_node)\n",
    "workflow.add_node(\"rag\", rag_node)\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "supervisor = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99acfe42-86a3-4ef3-aec2-841f210c3513",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message = {\"messages\": [{\"role\": \"user\", \"content\": \"What are our top 3 forecasted raw material shortages?\"}]}\n",
    "query_results = supervisor.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "642433d6-a484-44d8-8295-6f4b49e6afa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message = {\"messages\": [{\"role\": \"user\", \"content\": \"What is Apache Spark?\"}]}\n",
    "query_results = supervisor.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11f1cbf7-21bc-4a05-80ea-9475746e63a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message = {\"messages\": [{\"role\": \"user\", \"content\": \"What are our top 3 forecasted raw material shortages? Can you also tell me what Apache Spark is?\"}]}\n",
    "query_results = supervisor.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88eeded1-6fa6-4a62-9f29-da3128aa2ffd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dd058ca-33c6-4652-bd78-821e268a633e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def call_genie(state: ChatAgentState):\n",
    "  result = genie_agent.invoke(state)\n",
    "  return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": result[\"messages\"][-1].content,\n",
    "                \"name\": genie_config['name'],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "  \n",
    "graph_builder = StateGraph(ChatAgentState)\n",
    "graph_builder.add_node(\"Genie\", call_genie)\n",
    "graph_builder.add_edge(START, \"Genie\")\n",
    "graph_builder.add_edge(\"Genie\", END)\n",
    "app = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9290f467-9115-4af3-8376-8bbe2894c05f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2f3830c-abc0-42c2-a42a-bccc4102edae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "follow_up = {\"messages\": query_results['messages'] + [{\"role\": \"user\", \"content\": \"What about the top 10?\"}]}\n",
    "follow_up_results = app.invoke(follow_up)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fadeb2d5-55d2-41fd-b7d6-9b7017e952d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query_results['messages'][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "794ba0b4-ed24-4e6b-99e6-8dc4b485000f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agents.genie.resources.genie_room import genie_agent\n",
    "\n",
    "message = {\"messages\": [{\"role\": \"user\", \"content\": \"What are our top 3 forecasted raw material shortages?\"}]}\n",
    "query_results = genie_agent.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d103d2c-89d3-4240-abdc-74925dc5fc85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "debca96a-f847-4f37-b730-36a2a3c2b82a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43d05c64-ed1c-4f5d-8298-51173c23fa65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Router(TypedDict):\n",
    "    next: Literal[*options]\n",
    "\n",
    "question = [{\"role\": \"user\", \"content\": \"What are our top 3 forecasted raw material shortages?\"}]\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + question\n",
    "\n",
    "supervisor_model = model.with_structured_output(Router)\n",
    "next_response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4e96382-ceb0-439f-8cf3-606fbc2c0213",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "next_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4a61912-9390-4fc8-913f-030c8bcff5ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "member_agents = [\"rag\", \"genie\"]\n",
    "options = member_agents + [\"FINISH\"]\n",
    "\n",
    "system_prompt = f\"\"\"You are a supervisor tasked with managing a conversation between the following workers: {member_agents}. The worker's capabilities are as follows.\n",
    "                 \n",
    "    - genie: Performs text to SQL against supply chain data tables. \n",
    "    - rag: Retrieves documentation related to Databricks and Apache Spark.\n",
    "\n",
    "Given the following user request respond with the worker to act next. Each worker will perform a task and respond with their results and status. Call only the worker(s) that are important to the user's qeustion. Do not provide insights or summaries of the data returned by the workes. Your only job is to return the work names only. When finished respond with FINISH.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def supervisor_node(state: ChatAgentState) -> Command[Literal[*member_agents, \"__end__\"]]:\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state['messages']\n",
    "    supervisor_model = model.with_structured_output(Router)\n",
    "    response = supervisor_model.invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    #goto = response.content\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "    return Command(goto=goto, update={\"next\": goto})\n",
    "  \n",
    "\n",
    "def rag_node(state: ChatAgentState):\n",
    "  response = rag_agent.invoke(state)\n",
    "  return Command(\n",
    "        update={\"messages\": response['messages']},\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def genie_node(state: ChatAgentState):\n",
    "  response = genie_agent.invoke(state)\n",
    "  return Command(\n",
    "        update={\"messages\": response['messages']},\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "  \n",
    "#workflow.add_node(\"final_answer\", final_answer)\n",
    "\n",
    "workflow = StateGraph(ChatAgentState)\n",
    "workflow.add_node(\"supervisor\", supervisor_node)\n",
    "workflow.add_node(\"genie\", genie_node)\n",
    "workflow.add_node(\"rag\", rag_node)\n",
    "workflow.add_edge(START, \"supervisor\")\n",
    "supervisor = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "197263b7-1588-4c96-bcac-4ea22b718ce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "supervisor_results = supervisor.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What are our top 3 forecasted raw material shortages?. Can. you also tell me if Apache Spark supports streaming?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "399edeef-eab4-4996-a4ac-6713b335898b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agents.genie.resources.genie_room import genie_agent\n",
    "\n",
    "query_results = genie_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What are our top 3 forecasted raw material shortages?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b66dc78-9a58-4e38-b2e3-4515cde5eb6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "genie_result = genie_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What are our top 3 forecasted raw material shortages\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22d64b56-d161-4f36-9de5-474a88b22f23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "genie_result['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0775f0c9-904f-494a-85e1-b9709647f006",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "genie_messages = {\"messages\": genie_result['messages'] + \n",
    "                         [{\"role\": \"user\", \"content\": \"What about the top 5?\"}]}\n",
    "\n",
    "genie_follow_up = genie_agent.invoke(genie_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94887b01-101a-440d-83e7-9b6320ba5b5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rag_result = rag_agent.invoke({\"messages\": [{\"role\": \"user\", \n",
    "                                             \"content\": \"Does apache spark support streaming?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "480b0b2f-3615-432a-99f3-b44b90a58be5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "messages = {\"messages\": [{\"role\": \"user\", \"content\": \"What are our top 3 forecasted raw material shortages\"}, \n",
    "                         {\"role\": \"assistant\", \"content\": result['messages'][0].content},\n",
    "                         {\"role\": \"user\", \"content\": \"What about the top 5?\"}]}\n",
    "\n",
    "follow_up = genie_agent.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccb5b625-27f9-4866-a581-a3f2b64b0328",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agents.genie.graph import app as genie_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ce70b4c-aa97-4b33-beb2-b974a96dc5ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "genie_agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"What are our top 3 forecasted raw material shortages\"}]})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "supervisor_genie_as_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
